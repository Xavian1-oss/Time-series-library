#!/usr/bin/env bash
set -euo pipefail

# ============== åŸºç¡€è®¾ç½® ==============
export CUDA_VISIBLE_DEVICES=0

SEQ_LEN=96
LABEL_LEN=48

ENC_IN=7
DEC_IN=7
C_OUT=7

EPOCHS=50
PATIENCE=7
BATCH=32
LR=1e-3

Q_VAL=3
TOP_K=5

DMODEL=64
NHEADS=8
ELAYERS=2
DLAYERS=1
DFF=2048

PATCH_LEN=16

# USE_DTW=--use_dtw
INVERSE=''

# ===== æƒ³æ‰¹é‡è·‘çš„ç»„åˆ =====
DATASETS=(Weather) # å¦‚æœè¦æµ‹è¯•ä¸åŒæ•°æ®é›†çš„è¯ï¼Œåœ¨æ‹¬å·é‡Œæ·»åŠ å³å¯
PRED_LENS=(96 192 336) # å¦‚æœè¦æµ‹è¯•ä¸åŒæ­¥é•¿çš„è¯ï¼Œåœ¨æ‹¬å·é‡Œæ·»åŠ å³å¯

# ===== å„æ•°æ®é›†è·¯å¾„ä¸é€šé“æ•°ï¼ˆæŒ‰ä½ çš„ç›®å½•æ”¹ï¼‰=====
dataset_setup () {
    local ds="$1"
    case "$ds" in
      ETTh1) ROOT="./dataset/ETT-small/"; CSV="ETTh1.csv"; ENC_IN=7; DEC_IN=7; C_OUT=7;;
      ETTh2) ROOT="./dataset/ETT-small/"; CSV="ETTh2.csv"; ENC_IN=7; DEC_IN=7; C_OUT=7;;
      ETTm1) ROOT="./dataset/ETT-small/"; CSV="ETTm1.csv"; ENC_IN=7; DEC_IN=7; C_OUT=7;;
      ETTm2) ROOT="./dataset/ETT-small/"; CSV="ETTm2.csv"; ENC_IN=7; DEC_IN=7; C_OUT=7;;
      Weather)     ROOT="./dataset/weather/";       CSV="weather.csv";          ENC_IN=21;  DEC_IN=21;  C_OUT=21;;
      # Electricity) ROOT="./dataset/electricity/";   CSV="electricity.csv";      ENC_IN=321; DEC_IN=321; C_OUT=321;;
      # Exchange)    ROOT="./dataset/exchange_rate/"; CSV="exchange_rate.csv";    ENC_IN=8;   DEC_IN=8;   C_OUT=8;;
      # ILI)         ROOT="./dataset/ili/";           CSV="national_illness.csv"; ENC_IN=7;   DEC_IN=7;   C_OUT=7;;
      *) echo "æœªçŸ¥æ•°æ®é›†: $ds"; exit 1;;
    esac
}

# ============== æ—¥å¿—è®¾ç½® ==============
TS="$(date +'%Y%m%d_%H%M%S')"
LOG_DIR="./logs/multi_${TS}"
mkdir -p "${LOG_DIR}"

MASTER_LOG="${LOG_DIR}/master.log"
log() { echo "[$(date +'%F %T')] $*" | tee -a "${MASTER_LOG}"; }

trap 'ecode=$?; [ $ecode -ne 0 ] && log "âŒ è„šæœ¬å¼‚å¸¸é€€å‡ºï¼Œé€€å‡ºç =${ecode}"; exit $ecode' EXIT

run_with_log () {
    local baseline="$1"     # TimesNet / TimeMixer / DLinear
    local ds="$2"           # æ•°æ®é›†
    local pred="$3"         # é¢„æµ‹æ­¥é•¿

    dataset_setup "${ds}"

    # åˆ¤æ–­æ•°æ®é›†æ˜¯å¦ä¸ºè‡ªå®šä¹‰ç±»å‹
    local data_arg="${ds}"
    if [[ "${ds}" == "Weather" ]]; then
        data_arg="custom"
    fi

    local tag="${ds}_crc_${baseline,,}_m_pl${pred}_dm${DMODEL}"
    local log_file="${LOG_DIR}/${tag}.log"

    log "â–¶ï¸  å¼€å§‹è¿è¡Œï¼š${ds} / ${baseline} / pred_len=${pred}  (log: ${log_file})"

    # ------- ç”¨ heredoc å›æ˜¾å®Œæ•´å‘½ä»¤ï¼ˆé¿å… printf è§£æé€‰é¡¹çš„é—®é¢˜ï¼‰ -------
    {
      echo "CMD @ $(date +'%F %T')"
      cat <<EOF
python -u run.py \
  --task_name long_term_forecast \
  --is_training 1 \
  --model CRC \
  --baseline_model ${baseline} \
  --model_id ${tag} \
  --data ${data_arg} \
  --root_path ${ROOT} \
  --data_path ${CSV} \
  --features M \
  --seq_len ${SEQ_LEN} \
  --label_len ${LABEL_LEN} \
  --pred_len ${pred} \
  --enc_in ${ENC_IN} \
  --dec_in ${DEC_IN} \
  --c_out ${C_OUT} \
  --d_model ${DMODEL} \
  --n_heads ${NHEADS} \
  --e_layers ${ELAYERS} \
  --d_layers ${DLAYERS} \
  --d_ff ${DFF} \
  --patch_len "${PATCH_LEN}" \
  --batch_size ${BATCH} \
  --learning_rate ${LR} \
  --train_epochs ${EPOCHS} \
  --patience ${PATIENCE} \
  --use_gpu True \
  --gpu_type cuda \
  --gpu 0 \
  ${USE_DTW:-} ${INVERSE} \
  --q_val ${Q_VAL} \
  --top_k ${TOP_K} \
  --des CRC_${baseline}_M_d${DMODEL}
EOF
    } | tee -a "${log_file}" >> "${MASTER_LOG}"

    # ------- çœŸæ­£æ‰§è¡Œï¼ŒåŒæ­¥å†™å…¥ å•æ¨¡å‹æ—¥å¿— + æ€»æ—¥å¿— -------
    set +e
    python -u run.py \
      --task_name long_term_forecast \
      --is_training 1 \
      --model CRC \
      --baseline_model "${baseline}" \
      --model_id "${tag}" \
      --data "${data_arg}" \
      --root_path "${ROOT}" \
      --data_path "${CSV}" \
      --features M \
      --seq_len "${SEQ_LEN}" \
      --label_len "${LABEL_LEN}" \
      --pred_len "${pred}" \
      --enc_in "${ENC_IN}" \
      --dec_in "${DEC_IN}" \
      --c_out "${C_OUT}" \
      --d_model "${DMODEL}" \
      --n_heads "${NHEADS}" \
      --e_layers "${ELAYERS}" \
      --d_layers "${DLAYERS}" \
      --d_ff "${DFF}" \
      --patch_len "${PATCH_LEN}" \
      --batch_size "${BATCH}" \
      --learning_rate "${LR}" \
      --train_epochs "${EPOCHS}" \
      --patience "${PATIENCE}" \
      --use_gpu True \
      --gpu_type cuda \
      --gpu 0 \
      ${USE_DTW:-} ${INVERSE} \
      --q_val "${Q_VAL}" \
      --top_k "${TOP_K}" \
      --des "CRC_${baseline}_M_d${DMODEL}" \
      2> >(tee -a "${log_file}" >> "${MASTER_LOG}" >&2) \
      | tee -a "${log_file}" >> "${MASTER_LOG}"
    ecode=${PIPESTATUS[0]}
    set -e

    if [ $ecode -eq 0 ]; then
      log "âœ… å®Œæˆï¼š${ds} / ${baseline} / pred_len=${pred}"
    else
      log "âŒ å¤±è´¥ï¼š${ds} / ${baseline} / pred_len=${pred}ï¼Œé€€å‡ºç =${ecode}ï¼ˆè¯¦è§ ${log_file}ï¼‰"
      return $ecode
    fi
}

# ===== æ‰¹é‡ï¼šæ•°æ®é›† Ã— é¢„æµ‹æ­¥ Ã— åŸºçº¿ =====
for ds in "${DATASETS[@]}"; do
  for pl in "${PRED_LENS[@]}"; do
    run_with_log TimeXer "${ds}" "${pl}"
    run_with_log TimesNet "${ds}" "${pl}"
    run_with_log Autoformer "${ds}" "${pl}"
    run_with_log Informer  "${ds}" "${pl}"
    run_with_log PatchTST  "${ds}" "${pl}"
    run_with_log DLinear   "${ds}" "${pl}"
  done
done

log "ğŸ‰ å…¨éƒ¨æ‰¹é‡è¿è¡Œå®Œæˆã€‚æ—¥å¿—ç›®å½•ï¼š${LOG_DIR}"
